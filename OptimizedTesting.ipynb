{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1722186489745,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"mZmwXPAYPvCT","outputId":"9053de97-2d61-4ab9-daa1-b5e13cd4af11"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'MesoNet' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/DariusAf/MesoNet.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":949},"executionInfo":{"elapsed":23039,"status":"ok","timestamp":1722186489744,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"6Acgov32L7_b","outputId":"aa59d335-6651-422f-e948-628bdd4a4f5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ubuntu.com (185.125.190\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ubuntu.com (185.125.190\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,549 kB]\n","Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,420 kB]\n","Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,378 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,206 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,129 kB]\n","Fetched 16.1 MB in 2s (6,760 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libatlas-base-dev is already the newest version (3.10.3-12ubuntu1).\n","libx11-dev is already the newest version (2:1.7.5-1ubuntu0.3).\n","libx11-dev set to manually installed.\n","0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (71.0.4)\n","Collecting setuptools\n","  Using cached setuptools-71.1.0-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n","Using cached setuptools-71.1.0-py3-none-any.whl (2.3 MB)\n","Installing collected packages: setuptools\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 71.0.4\n","    Uninstalling setuptools-71.0.4:\n","      Successfully uninstalled setuptools-71.0.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed setuptools-71.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","pkg_resources","setuptools"]},"id":"a8b78623d27e4c7d9fa9244e00c55deb"}},"metadata":{}}],"source":["# Install system dependencies\n","!apt-get update\n","!apt-get install -y build-essential cmake\n","!apt-get install -y libx11-dev libatlas-base-dev\n","\n","\n","# Upgrade pip, setuptools, and wheel\n","!pip install --upgrade pip setuptools wheel\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29012,"status":"ok","timestamp":1722186518744,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"R63wBWwxYXr7","outputId":"83fdb4f8-b270-4b58-a315-82975093681c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566165 sha256=7700d1ca365a31386714f7a4692fbddd221c2c53ba572117f8763894bd30a82f\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"]}],"source":["# Install face_recognition\n","!pip install face_recognition"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2676,"status":"ok","timestamp":1722186521413,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"B1yfWF3MXr5H","outputId":"ec964b09-521a-4761-db2a-23675761d02b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n"]}],"source":["!pip install --upgrade dlib"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1722186521413,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"90w6qCmrQTMR","outputId":"0822bd95-aa7c-4302-8b3e-c56cfb1ea770"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current directory: /\n"]}],"source":["import os\n","\n","# Change to parent directory\n","os.chdir('..')\n","\n","# Verify the current working directory\n","print(\"Current directory:\", os.getcwd())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52322,"status":"ok","timestamp":1722186573724,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"xnVTpx6xUFUJ","outputId":"1f4beda1-df84-47bc-9b77-ace015a000be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting keras\n","  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n","  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n","  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n","Collecting namex (from keras)\n","  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n","Collecting optree (from keras)\n","  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.4.1 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 tensorboard-2.17.0 tensorflow-2.17.0\n"]}],"source":["pip install tensorflow keras --upgrade\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":873,"status":"ok","timestamp":1722186596867,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"gHsa3loIcLOb","outputId":"f272896f-6228-4b24-c5cc-3bc8a38b0741"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MesoNet\n"]}],"source":["cd MesoNet"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ttx9c-BV7s_p","executionInfo":{"status":"ok","timestamp":1722186627181,"user_tz":-330,"elapsed":6979,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["import numpy as np\n","from classifiers import *\n","from pipeline import *\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"jN-ULVwN7s8x","executionInfo":{"status":"ok","timestamp":1722186636916,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["# 1 - Load the model and its pretrained weights\n","classifier = Meso4()\n","classifier.load('weights/Meso4_DF.h5')"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":539,"status":"ok","timestamp":1722186982831,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"SiZr6iMb7s5D","outputId":"bb28ef35-b2ab-4a91-8109-415d1e288563"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 60 images belonging to 2 classes.\n"]}],"source":["# 2 - Minimial image generator\n","# We did use it to read and compute the prediction by batchs on test videos\n","# but do as you please, the models were trained on 256x256 images in [0,1]^(n*n)\n","\n","dataGenerator = ImageDataGenerator(rescale=1./255)\n","generator = dataGenerator.flow_from_directory(\n","        'test_images',\n","        target_size=(256, 256),\n","        batch_size=1,\n","        class_mode='binary',\n","        subset='training')"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1722186986325,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"n2ri0YOx7s3j","outputId":"6aafa4a7-1e63-422d-b55b-6d06758d3a80"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Predicted : [[0.05753862]] \n","Real class : [0.]\n"]}],"source":["# 3 - Predict\n","X, y = generator.__next__()\n","print('Predicted :', classifier.predict(X), '\\nReal class :', y)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1057,"status":"ok","timestamp":1722186991516,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"8Gl_Z-ItQIPT","outputId":"e5484f39-1602-4cac-deac-349eceb0ba7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{}\n"]}],"source":["\n","# 4 - Prediction for a image dataset\n","\n","classifier.load('weights/Meso4_F2F.h5')\n","\n","predictions = compute_accuracy(classifier, 'test_images')\n","print(predictions)\n","for video_name in predictions:\n","    print('`{}` video class prediction :'.format(video_name), predictions[video_name][0])\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"NBuo1uge8Gho","executionInfo":{"status":"ok","timestamp":1722187024917,"user_tz":-330,"elapsed":1577,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import cv2\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from classifiers import *\n","from pipeline import *\n","from sklearn.metrics import recall_score, accuracy_score\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"0Oct4qXC8GeU","executionInfo":{"status":"ok","timestamp":1722187027750,"user_tz":-330,"elapsed":969,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["# Load the model and its pretrained weights\n","classifier = Meso4()\n","classifier.load('weights/Meso4_DF.h5')"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"pvRn4ct_8Gcc","executionInfo":{"status":"ok","timestamp":1722187043932,"user_tz":-330,"elapsed":843,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["# Function to compute predictions for each class\n","def compute_accuracy(classifier, directory, use_optimization=True):\n","    predictions = {'real': [], 'fake': []}\n","    actual_labels = {'real': [], 'fake': []}\n","    filenames = {'real': [], 'fake': []}  # To store filenames\n","\n","    for class_folder in os.listdir(directory):\n","        class_path = os.path.join(directory, class_folder)\n","        if os.path.isdir(class_path):\n","            for filename in os.listdir(class_path):\n","                if filename.endswith('.jpg') or filename.endswith('.png'):\n","                    img_path = os.path.join(class_path, filename)\n","\n","                    # Optimize or resize image based on the flag\n","                    if use_optimization:\n","                        img = optimize_image(img_path)\n","                    else:\n","                        img = resize_image(img_path)\n","\n","                    # Convert image to array\n","                    img_array = img_to_array(img)\n","                    img_array = img_array / 255.0  # Normalize pixel values\n","                    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for batch\n","\n","                    # Predict using classifier\n","                    prediction = classifier.predict(img_array)\n","\n","                    if class_folder == 'real':\n","                        predictions['real'].append(prediction[0][0])\n","                        actual_labels['real'].append(1)  # 1 for real\n","                        filenames['real'].append(filename)  # Store filename\n","                    elif class_folder == 'df':\n","                        predictions['fake'].append(prediction[0][0])\n","                        actual_labels['fake'].append(0)  # 0 for fake\n","                        filenames['fake'].append(filename)  # Store filename\n","    return predictions, actual_labels, filenames\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Jx5ZORqM8GZC","executionInfo":{"status":"ok","timestamp":1722187058017,"user_tz":-330,"elapsed":807,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["# Function to optimize image using OpenCV (resize, blur, histogram equalization, CLAHE, and sharpening)\n","from skimage import exposure\n","from PIL import Image, ImageFilter\n","\n","import cv2\n","import numpy as np\n","from skimage import exposure\n","from PIL import Image, ImageFilter\n","\n","def optimize_image(img_path):\n","    # Read the image using OpenCV\n","    img = cv2.imread(img_path)\n","\n","    # Resize image to 256x256\n","    resized_img = cv2.resize(img, (256, 256))\n","\n","    # Convert to grayscale\n","    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Histogram Equalization\n","    equalized_img = cv2.equalizeHist(gray_img)\n","\n","    # Normalize the image (scikit-image)\n","    norm_img = exposure.rescale_intensity(equalized_img, out_range=(0, 255)).astype(np.uint8)\n","\n","    # Convert to RGB for consistency and apply sharpening (PIL)\n","    rgb_img = cv2.cvtColor(norm_img, cv2.COLOR_GRAY2RGB)\n","\n","    # Convert to LAB color space and enhance edges\n","    lab_img = cv2.cvtColor(np.array(rgb_img), cv2.COLOR_RGB2LAB)\n","    l_channel, a_channel, b_channel = cv2.split(lab_img)\n","    l_channel = cv2.equalizeHist(l_channel)  # Equalize the L channel\n","    lab_img = cv2.merge([l_channel, a_channel, b_channel])\n","    enhanced_img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2RGB)\n","\n","    # Convert back to OpenCV format\n","    optimized_img = np.array(enhanced_img)\n","\n","    return optimized_img"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"zv6sgFba8GXe","executionInfo":{"status":"ok","timestamp":1722187063407,"user_tz":-330,"elapsed":747,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["# Function to resize image without optimization\n","def resize_image(img_path):\n","    img = cv2.imread(img_path)\n","\n","    # Resize image to 256x256\n","    resized_img = cv2.resize(img, (256, 256))\n","\n","    return resized_img"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"4tO7-Hzx8GRN","executionInfo":{"status":"error","timestamp":1722191005069,"user_tz":-330,"elapsed":4928,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}},"outputId":"e6d9d6d2-7460-4aef-9e35-fe3a92c85fab"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'compute_accuracy' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6e9125ccfd8a>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Compute predictions, actual labels, and filenames for optimized images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mpredictions_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_labels_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_optimization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mpredictions_no_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_labels_no_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames_no_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_optimization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'compute_accuracy' is not defined"]}],"source":["import numpy as np\n","from sklearn.metrics import (\n","    accuracy_score, recall_score, precision_score, f1_score,\n","    confusion_matrix, matthews_corrcoef, balanced_accuracy_score\n",")\n","import matplotlib.pyplot as plt\n","\n","# Calculate metrics\n","def calculate_metrics(predictions, actual_labels):\n","    metrics = {}\n","    for class_type in ['real', 'fake']:\n","        predicted_classes = np.round(predictions[class_type])\n","        true_classes = np.array(actual_labels[class_type])\n","\n","        accuracy = accuracy_score(true_classes, predicted_classes)\n","        recall = recall_score(true_classes, predicted_classes, pos_label=1 if class_type == 'real' else 0)\n","        precision = precision_score(true_classes, predicted_classes, pos_label=1 if class_type == 'real' else 0)\n","        f1 = f1_score(true_classes, predicted_classes, pos_label=1 if class_type == 'real' else 0)\n","        mcc = matthews_corrcoef(true_classes, predicted_classes)\n","        balanced_acc = balanced_accuracy_score(true_classes, predicted_classes)\n","\n","        metrics[class_type] = {\n","            'accuracy': accuracy,\n","            'recall': recall,\n","            'precision': precision,\n","            'f1': f1,\n","            'mcc': mcc,\n","            'balanced_accuracy': balanced_acc\n","        }\n","\n","    return metrics\n","\n","# Calculate overall metrics\n","def calculate_overall_metrics(predictions, actual_labels):\n","    predicted_classes = np.concatenate([np.round(predictions['real']), np.round(predictions['fake'])])\n","    true_classes = np.concatenate([np.array(actual_labels['real']), np.array(actual_labels['fake'])])\n","\n","    accuracy = accuracy_score(true_classes, predicted_classes)\n","    recall = recall_score(true_classes, predicted_classes, pos_label=1)  # Assuming 'real' is labeled as 1\n","    precision = precision_score(true_classes, predicted_classes, pos_label=1)  # Assuming 'real' is labeled as 1\n","    f1 = f1_score(true_classes, predicted_classes, pos_label=1)  # Assuming 'real' is labeled as 1\n","    mcc = matthews_corrcoef(true_classes, predicted_classes)\n","    balanced_acc = balanced_accuracy_score(true_classes, predicted_classes)\n","    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","\n","    return accuracy, recall, precision, f1, mcc, balanced_acc, conf_matrix\n","\n","# Visualize metrics\n","def visualize_metrics(metrics_opt, metrics_no_opt, overall_metrics_opt, overall_metrics_no_opt):\n","    categories = ['Real', 'Fake', 'Overall']\n","    metrics_to_plot = ['accuracy', 'recall', 'precision', 'f1', 'mcc', 'balanced_accuracy']\n","    metric_titles = {\n","        'accuracy': 'Accuracy', 'recall': 'Recall', 'precision': 'Precision',\n","        'f1': 'F1 Score', 'mcc': 'MCC', 'balanced_accuracy': 'Balanced Accuracy'\n","    }\n","\n","    x = np.arange(len(categories))\n","    width = 0.35\n","    num_metrics = len(metrics_to_plot)\n","\n","    fig, ax = plt.subplots(num_metrics, 1, figsize=(10, 5 * num_metrics))\n","\n","    for idx, metric in enumerate(metrics_to_plot):\n","        values_opt = [\n","            metrics_opt['real'].get(metric, 0),\n","            metrics_opt['fake'].get(metric, 0),\n","            overall_metrics_opt[idx]\n","        ]\n","        values_no_opt = [\n","            metrics_no_opt['real'].get(metric, 0),\n","            metrics_no_opt['fake'].get(metric, 0),\n","            overall_metrics_no_opt[idx]\n","        ]\n","\n","        ax[idx].bar(x - width/2, values_opt, width, label='Optimized', color='blue')\n","        ax[idx].bar(x + width/2, values_no_opt, width, label='Non-Optimized', color='orange')\n","        ax[idx].set_xticks(x)\n","        ax[idx].set_xticklabels(categories)\n","        ax[idx].set_ylabel(metric_titles[metric])\n","        ax[idx].set_ylim(0, 1)\n","        ax[idx].set_title(f'{metric_titles[metric]} Comparison')\n","        ax[idx].legend()\n","\n","        for i in range(len(categories)):\n","            opt_value = values_opt[i]\n","            no_opt_value = values_no_opt[i]\n","\n","            if opt_value is not None:\n","                ax[idx].text(i - width/2, opt_value + 0.02, f'{opt_value * 100:.2f}%', ha='center', color='black', fontsize=10)\n","            else:\n","                ax[idx].text(i - width/2, 0.5, 'N/A', ha='center', color='black', fontsize=10)\n","\n","            if no_opt_value is not None:\n","                ax[idx].text(i + width/2, no_opt_value + 0.02, f'{no_opt_value * 100:.2f}%', ha='center', color='black', fontsize=10)\n","            else:\n","                ax[idx].text(i + width/2, 0.5, 'N/A', ha='center', color='black', fontsize=10)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Compute predictions, actual labels, and filenames for optimized images\n","predictions_opt, actual_labels_opt, filenames_opt = compute_accuracy(classifier, 'test_images', use_optimization=True)\n","predictions_no_opt, actual_labels_no_opt, filenames_no_opt = compute_accuracy(classifier, 'test_images', use_optimization=False)\n","\n","metrics_opt = calculate_metrics(predictions_opt, actual_labels_opt)\n","overall_metrics_opt = calculate_overall_metrics(predictions_opt, actual_labels_opt)\n","\n","metrics_no_opt = calculate_metrics(predictions_no_opt, actual_labels_no_opt)\n","overall_metrics_no_opt = calculate_overall_metrics(predictions_no_opt, actual_labels_no_opt)\n","\n","\n","print(\"\\nOverall Metrics (Optimized):\")\n","print(f\"Accuracy: {overall_metrics_opt[0]:.4f}\")\n","print(f\"Recall: {overall_metrics_opt[1]:.4f}\")\n","print(f\"Precision: {overall_metrics_opt[2]:.4f}\")\n","print(f\"F1 Score: {overall_metrics_opt[3]:.4f}\")\n","print(f\"MCC: {overall_metrics_opt[4]:.4f}\")\n","print(f\"Balanced Accuracy: {overall_metrics_opt[5]:.4f}\")\n","print(f\"Confusion Matrix:\\n{overall_metrics_opt[6]}\")\n","\n","\n","print(\"\\nOverall Metrics (Non-Optimized):\")\n","print(f\"Accuracy: {overall_metrics_no_opt[0]:.4f}\")\n","print(f\"Recall: {overall_metrics_no_opt[1]:.4f}\")\n","print(f\"Precision: {overall_metrics_no_opt[2]:.4f}\")\n","print(f\"F1 Score: {overall_metrics_no_opt[3]:.4f}\")\n","print(f\"MCC: {overall_metrics_no_opt[4]:.4f}\")\n","print(f\"Balanced Accuracy: {overall_metrics_no_opt[5]:.4f}\")\n","print(f\"Confusion Matrix:\\n{overall_metrics_no_opt[6]}\")\n","\n","# Visualize the metrics\n","visualize_metrics(metrics_opt, metrics_no_opt, overall_metrics_opt, overall_metrics_no_opt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbqNA5i38hgv","executionInfo":{"status":"aborted","timestamp":1722186573731,"user_tz":-330,"elapsed":42,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Visualize metrics\n","def visualize_metrics(metrics_opt, metrics_no_opt, overall_accuracy_opt, overall_recall_opt, overall_accuracy_no_opt, overall_recall_no_opt):\n","    categories = ['Real', 'Fake', 'Overall']\n","    accuracies_opt = [metrics_opt['real']['accuracy'], metrics_opt['fake']['accuracy'], overall_accuracy_opt]\n","    recalls_opt = [metrics_opt['real']['recall'], metrics_opt['fake']['recall'], overall_recall_opt]\n","    accuracies_no_opt = [metrics_no_opt['real']['accuracy'], metrics_no_opt['fake']['accuracy'], overall_accuracy_no_opt]\n","    recalls_no_opt = [metrics_no_opt['real']['recall'], metrics_no_opt['fake']['recall'], overall_recall_no_opt]\n","\n","    x = np.arange(len(categories))\n","    width = 0.35\n","\n","    fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n","\n","    # Accuracy comparison - Bar chart\n","    ax[0].bar(x - width/2, accuracies_opt, width, label='Optimized', color='blue')\n","    ax[0].bar(x + width/2, accuracies_no_opt, width, label='Non-Optimized', color='orange')\n","    ax[0].set_xticks(x)\n","    ax[0].set_xticklabels(categories)\n","    ax[0].set_ylabel('Accuracy')\n","    ax[0].set_ylim(0, 1)\n","    ax[0].set_title('Accuracy Comparison')\n","    ax[0].legend()\n","\n","    for i in range(len(categories)):\n","        ax[0].text(i - width/2, accuracies_opt[i] / 2, f'{accuracies_opt[i] * 100:.2f}%', ha='center', color='white', fontsize=12)\n","        ax[0].text(i + width/2, accuracies_no_opt[i] / 2, f'{accuracies_no_opt[i] * 100:.2f}%', ha='center', color='white', fontsize=12)\n","\n","    # Recall comparison - Bar chart\n","    ax[1].bar(x - width/2, recalls_opt, width, label='Optimized', color='blue')\n","    ax[1].bar(x + width/2, recalls_no_opt, width, label='Non-Optimized', color='orange')\n","    ax[1].set_xticks(x)\n","    ax[1].set_xticklabels(categories)\n","    ax[1].set_ylabel('Recall')\n","    ax[1].set_ylim(0, 1)\n","    ax[1].set_title('Recall Comparison')\n","    ax[1].legend()\n","\n","    for i in range(len(categories)):\n","        ax[1].text(i - width/2, recalls_opt[i] / 2, f'{recalls_opt[i] * 100:.2f}%', ha='center', color='white', fontsize=12)\n","        ax[1].text(i + width/2, recalls_no_opt[i] / 2, f'{recalls_no_opt[i] * 100:.2f}%', ha='center', color='white', fontsize=12)\n","\n","    # Line graphs for accuracy and recall\n","    ax[2].plot(categories, accuracies_opt, marker='o', label='Accuracy Optimized', color='blue')\n","    ax[2].plot(categories, accuracies_no_opt, marker='o', label='Accuracy Non-Optimized', color='orange')\n","    ax[2].plot(categories, recalls_opt, marker='x', label='Recall Optimized', color='green')\n","    ax[2].plot(categories, recalls_no_opt, marker='x', label='Recall Non-Optimized', color='red')\n","    ax[2].set_xticks(x)\n","    ax[2].set_xticklabels(categories)\n","    ax[2].set_ylabel('Metrics')\n","    ax[2].set_ylim(0, 1)\n","    ax[2].set_title('Line Graphs for Accuracy and Recall')\n","    ax[2].legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Compute predictions, actual labels, and filenames for optimized images\n","predictions_opt, actual_labels_opt, filenames_opt = compute_accuracy(classifier, 'test_images', use_optimization=True)\n","metrics_opt = calculate_metrics(predictions_opt, actual_labels_opt)\n","overall_accuracy_opt, overall_recall_opt = calculate_overall_metrics(predictions_opt, actual_labels_opt)\n","\n","# Compute predictions, actual labels, and filenames for non-optimized images\n","predictions_no_opt, actual_labels_no_opt, filenames_no_opt = compute_accuracy(classifier, 'test_images', use_optimization=False)\n","metrics_no_opt = calculate_metrics(predictions_no_opt, actual_labels_no_opt)\n","overall_accuracy_no_opt, overall_recall_no_opt = calculate_overall_metrics(predictions_no_opt, actual_labels_no_opt)\n","\n","# Visualize the metrics\n","visualize_metrics(metrics_opt, metrics_no_opt, overall_accuracy_opt, overall_recall_opt, overall_accuracy_no_opt, overall_recall_no_opt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1722186573731,"user":{"displayName":"Shubham Sharma","userId":"17028427270447765456"},"user_tz":-330},"id":"PjjR2rvtXjq2"},"outputs":[],"source":["# Print metrics\n","print(f\"Optimized Accuracy (Real): {metrics_opt['real']['accuracy'] * 100:.2f}%\")\n","print(f\"Optimized Accuracy (Fake): {metrics_opt['fake']['accuracy'] * 100:.2f}%\")\n","print(f\"Optimized Overall Accuracy: {overall_accuracy_opt * 100:.2f}%\")\n","print(f\"Optimized Recall (Real): {metrics_opt['real']['recall'] * 100:.2f}%\")\n","print(f\"Optimized Recall (Fake): {metrics_opt['fake']['recall'] * 100:.2f}%\")\n","print(f\"Optimized Overall Recall: {overall_recall_opt * 100:.2f}%\")\n","\n","print(f\"Non-Optimized Accuracy (Real): {metrics_no_opt['real']['accuracy'] * 100:.2f}%\")\n","print(f\"Non-Optimized Accuracy (Fake): {metrics_no_opt['fake']['accuracy'] * 100:.2f}%\")\n","print(f\"Non-Optimized Overall Accuracy: {overall_accuracy_no_opt * 100:.2f}%\")\n","print(f\"Non-Optimized Recall (Real): {metrics_no_opt['real']['recall'] * 100:.2f}%\")\n","print(f\"Non-Optimized Recall (Fake): {metrics_no_opt['fake']['recall'] * 100:.2f}%\")\n","print(f\"Non-Optimized Overall Recall: {overall_recall_no_opt * 100:.2f}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOdwUp6fMD1JlKLlb8QnWpJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}